Introduction
This project aims to perform a text analysis on 10 open-access articles using the Grobid tool. The analysis focuses on three specific aspects:

Generate a keyword cloud based on the abstracts of the articles.
Visualize the number of figures present in each article.
List the links found in the articles.
The purpose of this document is to explain how the answers generated by the implemented scripts were validated, the decisions made during the process, and how correct results were ensured.

Selection of Articles
To perform the analysis, 10 open-access articles were selected from reliable repositories such as PubMed Central and arXiv. This selection was random, but with the assurance that the articles had enough data and quality for processing with Grobid. The main topic of the selected articles is Data Science.

The articles were processed using the Grobid service, which is a tool for extracting structured information (such as bibliographies, references, sections, figures, etc.) from scientific documents in PDF format.

1. Keyword Cloud Based on Abstracts
To create the keyword cloud, the abstracts of the articles were first extracted using the Grobid service. Then, these texts were processed and a word cloud was generated using the WordCloud library in Python.

Data Validation: Each abstract was reviewed to ensure that Grobid had extracted it correctly and that it did not contain errors or incomplete fragments.
Result Review: The content of the word cloud was compared with the article abstracts to verify that the most relevant words were prominent in the visualization.
2. Visualization of the Number of Figures per Article
For this analysis, Grobid was used to extract the content of the articles and specifically identify the figures. The number of figures per article was then visualized using matplotlib.

Figure Extraction Validation: It was validated that the number of figures reported by Grobid matched the actual number of figures observed in the PDFs.
Consistency of Results: To ensure that Grobid was correctly identifying the figures, some extractions of articles were randomly reviewed and compared with the original documents.
Challenges and Solutions:

3. List of Links Found in the Articles
Link Extraction Validation: It was verified that all extracted links corresponded to valid URLs. This was done by comparing the links with a manually extracted list of external links.
Link Checking: Each link was checked to ensure that it was accessible and not broken (although an exhaustive validation of all links was not performed, some links were randomly tested).
Reproducibility Tests:
All scripts were executed in a clean environment (both in the Docker container and in a Python virtual environment) to ensure that the installation and execution instructions were correct and reproducible.
The generated outputs (word cloud, figure charts, and list of links) were validated in multiple environments to ensure that the results were consistent.

